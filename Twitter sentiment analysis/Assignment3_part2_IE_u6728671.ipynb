{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Part 2: IE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment, the task is to code a Named Entity Recognizer (NER) application in Python using the CRFsuite library.\n",
    "\n",
    "It is recommended you complete the Named_Entity_Extraction_Tutorial.ipynb tutorial before attemping this.\n",
    "\n",
    "Your tasks for this assignment are to:\n",
    "1. Build a NER classifier following the tutorial.\n",
    "2. Improve the performance of your NER classifier.\n",
    "3. Answer three written assignments.\n",
    "\n",
    "* Write answers in this notebook file, and upload the file to Wattle submission site. **Please rename and submit jupyter notebook file (Assignment5.ipynb) to your_uid.ipynb (e.g. u6000001.ipynb) with your written answers therein**. Do not upload any other files to Wattle except this notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Question 1 (2 points) Build a NER model <a id='Task1'></a> </span>\n",
    "### Part A (1.5 marks)\n",
    "\n",
    "* Build a NER model using the train and test data files.\n",
    "* You can use the code provided in [tutorial sheet](Named_Entity_Extraction_Tutorial.ipynb) \n",
    "* Try changing the feature extraction, model hyper parameters, or other settings in order to improve your model performance.\n",
    "* Marks will be awarded based on how well your model performs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test data loaded succesfully!\n",
      "Feature Extraction done!\n",
      "Training done :)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      0.80      0.80      2039\n",
      "       I-LOC       0.72      0.70      0.71       775\n",
      "      B-MISC       0.59      0.73      0.65       707\n",
      "      I-MISC       0.58      0.50      0.54      1447\n",
      "       B-ORG       0.82      0.87      0.84      3043\n",
      "       I-ORG       0.81      0.78      0.80      2316\n",
      "       B-PER       0.89      0.90      0.90      1892\n",
      "       I-PER       0.93      0.91      0.92      1662\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     13881\n",
      "   macro avg       0.77      0.77      0.77     13881\n",
      "weighted avg       0.80      0.80      0.80     13881\n",
      " samples avg       0.10      0.10      0.10     13881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import io\n",
    "import nltk\n",
    "import scipy\n",
    "import codecs\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def sent2features(sent, feature_func):\n",
    "    return [feature_func(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [s[-1] for s in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [s[0] for s in sent]\n",
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(y_true)\n",
    "    y_pred_combined = lb.transform(y_pred)\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "            \n",
    "def word2simple_features(sent, i):\n",
    "    '''\n",
    "    This makes a simple baseline.  \n",
    "    You can add and/or remove features to get (much?) better results.\n",
    "    Experiment with it as you will need to do this for assignment.\n",
    "    '''\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, # This feature is constant for all words.\n",
    "        'word.lower()': word.lower(), # This feature is the word, ignoring case.\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[3:]': word[3:],\n",
    "        'word.isalpha()': word.isalpha(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "    }\n",
    "    if i == 0:\n",
    "        features['BOS'] = True # Mark the beginning of sentence.\n",
    "        \n",
    "    if i == len(sent)-1:\n",
    "        features['EOS'] = True # Mark the end of sentence.\n",
    "\n",
    "    return features\n",
    "\n",
    "# load data and preprocess\n",
    "def extract_data(path):\n",
    "    \"\"\"\n",
    "    Extracting data from train file or test file. \n",
    "    path - the path of the file to extract\n",
    "    \n",
    "    return:\n",
    "        res - a list of sentences, each sentence is a\n",
    "              a list of tuples. For train file, each tuple\n",
    "              contains token and label. For test file, each\n",
    "              tuple only contains token.\n",
    "        ids - a list of ids for the corresponding token. This\n",
    "              is mainly for Kaggle submission.\n",
    "    \"\"\"\n",
    "    file = io.open(path, mode=\"r\", encoding=\"utf-8\")\n",
    "    next(file)\n",
    "    res = []\n",
    "    ids = []\n",
    "    sent = []\n",
    "    for line in file:\n",
    "        if line != '\\n':\n",
    "            # Each line contains the position ID, the token, and (for the training set) the label.\n",
    "            parts = line.strip().split(' ')\n",
    "            sent.append(tuple(parts[1:]))\n",
    "            ids.append(parts[0])\n",
    "        else:\n",
    "            res.append(sent)\n",
    "            sent = []\n",
    "                \n",
    "    return res, ids\n",
    "\n",
    "# Load train and test data\n",
    "train_data, train_ids = extract_data('train')\n",
    "test_data, test_ids = extract_data('test')\n",
    "\n",
    "# Load true labels for test data\n",
    "test_labels = list(pd.read_csv('test_ground_truth').loc[:, 'label'])\n",
    "\n",
    "print('Train and Test data loaded succesfully!')\n",
    "\n",
    "# Feature extraction using the word2simple_features function\n",
    "train_features = [sent2features(s, feature_func=word2simple_features) for s in train_data]\n",
    "train_labels = [sent2labels(s) for s in train_data]\n",
    "test_features = [sent2features(s, feature_func=word2simple_features) for s in test_data]\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(train_features, train_labels):\n",
    "    trainer.append(xseq, yseq)\n",
    "print('Feature Extraction done!')    \n",
    "\n",
    "# Explore the extracted features    \n",
    "sent2features(train_data[0], word2simple_features)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 0.01,   # coefficient for L1 penalty\n",
    "    'c2': 0.1,  # coefficient for L2 penalty\n",
    "    'max_iterations': 100,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': False,\n",
    "    'feature.possible_states': True\n",
    "})\n",
    "\n",
    "trainer.train('ner-esp.model')\n",
    "\n",
    "print('Training done :)')\n",
    "\n",
    "# Make predictions\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('ner-esp.model')\n",
    "test_pred = [tagger.tag(xseq) for xseq in test_features]\n",
    "test_pred = [s for w in test_pred for s in w]\n",
    "\n",
    "## Print evaluation\n",
    "print(bio_classification_report(test_pred, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above cell should look something like this (but with different numbers)\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "      B-LOC       0.68      0.47      0.55      1084\n",
    "      I-LOC       0.52      0.25      0.34       325\n",
    "     B-MISC       0.54      0.11      0.19       339\n",
    "     I-MISC       0.54      0.22      0.32       557\n",
    "      B-ORG       0.76      0.51      0.61      1400\n",
    "      I-ORG       0.67      0.44      0.53      1104\n",
    "      B-PER       0.73      0.68      0.71       735\n",
    "      I-PER       0.78      0.82      0.80       634\n",
    "\n",
    "avg / total       0.68      0.48      0.55      6178\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B (0.5 marks)\n",
    "\n",
    "Briefly explain what changes to your model you tried and how these changes affected the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The following features were added\n",
    "1) word.lower()\n",
    "\n",
    "2) word.isdigit()\n",
    "\n",
    "3) word[-3:]\n",
    "\n",
    "4) word[3:]\n",
    "\n",
    "5) word.isalpha()\n",
    "\n",
    "6) word.isupper()\n",
    "\n",
    "7) word.istitle()\n",
    "\n",
    "The performance of the model was increased by a small amount on adding these features. The performance of the model increased drastically by making changes to the hyper-parameters of the model as follows.\n",
    "\n",
    "1) c1 : 0.01\n",
    "\n",
    "2) c2 : 0.1\n",
    "\n",
    "3) max_iterations : 100\n",
    "\n",
    "4) feature.possible_transitions : False\n",
    "\n",
    "5) feature.possible_states : True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Written Part (3 points) </span>\n",
    "\n",
    "Answer briefly and concisely the following questions.\n",
    "Check [this](https://sourceforge.net/p/jupiter/wiki/markdown_syntax/#md_ex_lists) if you are not familiar with markdown syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (0.5 point)\n",
    "Think of three relevant baselines for the Named Entity Classification task.\n",
    "Provide answers using bullet list with 3 items. Give a short description of each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (1.5 point)\n",
    "How does Maximal Marginal Relevance (MMR) address redundancy issues? (0.5 point)\n",
    "\n",
    "How can you tell MMR that \"Sydney\" and \"Melbourne\" are cities? (0.5 points)\n",
    "\n",
    "How can you tell MMR that \"solar panels\" and \"photovoltaic cells\" have similar meaning? (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "1) Given a corpus, an information retrieval system will retrieve a set of documents that are relevent to a query. The retrieved documents often contains data that overlap with other retrieved documents and therefore is not desirable in some cases (Example : Summarization). In these cases, MMR can be used. MMR compares all the retrieved documents with each other and selects one that is relevent to the query and overlaps the least with other retrieved documents.\n",
    "\n",
    "2) The lambda parameter in MMR equation can be used to convey the model that \"Sydeny\" and \"Melbourne\" are both cities. Setting the lambda to a low value (~0.3) will be appropriate in this case. This means that the MMR model will retrieve data that is relevent yet diverse enough as to not differentiate \"Sydney\" and \"Melbourne\" as entities with completely different context. Apart from changing the lambda value, the similarity can be measure using knowledge based similarity, which can be useful as it can calculate similarity based on context.\n",
    "\n",
    "3) Similar meanings for the word \"solar panels\" and \"photovoltaic cells\" can be achieved by setting a high lambda value. This means that the model will retrieve data from a collection that are less diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (1 point)\n",
    "\n",
    "Imagine you are developing an extractive text summarization tool using HMM.\n",
    "\n",
    "What are the hidden states and the observations of the HMM model? (0.5 point)\n",
    "\n",
    "Which algorithm is used to compute the probability of a particular observation sequence? (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "1) The observation state is summaries of known text data and the hidden state is the text itself that has not been summarised.\n",
    "\n",
    "2) Forward Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
